{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of arXiv Abstracts Using BERT Models\n",
    "\n",
    "Levent Güner <leventg@kth.se>\n",
    "\n",
    "I. Erdem Demir <iedemir@kth.se>\n",
    "\n",
    "### How to run the code?\n",
    "\n",
    "* Download the data from https://www.kaggle.com/Cornell-University/arxiv\n",
    "* Install the required libraries\n",
    "* Run the lines one by one\n",
    "* Google Colab is recommended after Part 3. The code is written for loading the data from Google Drive.\n",
    "* The BERT part is both written for BERT Base Model and SciBERT.\n",
    "* In sections 3.2 and 3.4.1, Change the required parts to use SciBERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages (4.15.0)\r\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (2.26.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (21.2)\r\n",
      "Collecting tokenizers<0.11,>=0.10.1\r\n",
      "  Using cached tokenizers-0.10.3-cp39-cp39-macosx_12_0_arm64.whl\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages (from transformers) (4.62.3)\r\n",
      "Requirement already satisfied: filelock in /Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages (from transformers) (3.4.2)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages (from transformers) (0.2.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages (from transformers) (2021.11.10)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (1.21.4)\r\n",
      "Requirement already satisfied: sacremoses in /Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages (from transformers) (0.0.46)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\r\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from packaging>=20.0->transformers) (2.4.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (2.0.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\r\n",
      "Requirement already satisfied: click in /Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.3)\r\n",
      "Requirement already satisfied: six in /Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages (from sacremoses->transformers) (1.15.0)\r\n",
      "Requirement already satisfied: joblib in /Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\r\n",
      "Installing collected packages: tokenizers\r\n",
      "Successfully installed tokenizers-0.10.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import dask.bag as db\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "import sklearn.metrics as mt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import sklearn.model_selection as ms\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding,  Dropout,  SpatialDropout1D, LSTM\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "\n",
    "from tqdm import trange\n",
    "import pickle\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define text cleaner\n",
    "\n",
    "class CleanText(BaseEstimator, TransformerMixin):\n",
    "    def remove_mentions(self, input_text):\n",
    "        return re.sub(r'@\\w+', '', input_text)\n",
    "    \n",
    "    def remove_urls(self, input_text):\n",
    "        return re.sub(r'http.?://[^\\s]+[\\s]?', '', input_text)\n",
    "    \n",
    "    def emoji_oneword(self, input_text):\n",
    "        # By compressing the underscore, the emoji is kept as one word\n",
    "        return input_text.replace('_','')\n",
    "    \n",
    "    def remove_punctuation(self, input_text):\n",
    "        # Make translation table\n",
    "        punct = string.punctuation\n",
    "        trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n",
    "        return input_text.translate(trantab)\n",
    "    def remove_digits(self, input_text):\n",
    "        return re.sub('\\d+', '', input_text)\n",
    "    \n",
    "    def to_lower(self, input_text):\n",
    "        return input_text.lower()\n",
    "    \n",
    "    def remove_stopwords(self, input_text):\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        # Some words which might indicate a certain sentiment are kept via a whitelist\n",
    "        whitelist = [\"n't\", \"not\", \"no\"]\n",
    "        words = input_text.split() \n",
    "        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
    "        return \" \".join(clean_words) \n",
    "    \n",
    "    def stemming(self, input_text):\n",
    "        porter = PorterStemmer()\n",
    "        words = input_text.split() \n",
    "        stemmed_words = [porter.stem(word) for word in words]\n",
    "        return \" \".join(stemmed_words)\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        clean_X = X.apply(self.remove_mentions).apply(self.remove_urls).apply(self.emoji_oneword).apply(self.remove_punctuation).apply(self.remove_digits).apply(self.to_lower).apply(self.remove_stopwords)\n",
    "        return clean_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/erdemdemir/Desktop/scalable-projects/ID2223-Final-Levent_Güner-Erdem_Demir/arxiv-metadata-oai-snapshot.json'\n\nTraceback\n---------\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/local.py\", line 220, in execute_task\n    result = _execute_task(task, data)\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/core.py\", line 119, in _execute_task\n    return func(*(_execute_task(a, cache) for a in args))\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/core.py\", line 119, in <genexpr>\n    return func(*(_execute_task(a, cache) for a in args))\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/core.py\", line 113, in _execute_task\n    return [_execute_task(a, cache) for a in arg]\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/core.py\", line 113, in <listcomp>\n    return [_execute_task(a, cache) for a in arg]\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/core.py\", line 119, in _execute_task\n    return func(*(_execute_task(a, cache) for a in args))\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/bag/core.py\", line 2440, in empty_safe_apply\n    _, part = peek(part)\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/toolz/itertoolz.py\", line 1000, in peek\n    item = next(iterator)\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/bag/core.py\", line 2012, in __next__\n    vals = [next(i) for i in self.iters]\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/bag/core.py\", line 2012, in <listcomp>\n    vals = [next(i) for i in self.iters]\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/bag/text.py\", line 164, in file_to_blocks\n    with lazy_file as f:\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/fsspec/core.py\", line 103, in __enter__\n    f = self.fs.open(self.path, mode=mode)\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/fsspec/spec.py\", line 1030, in open\n    f = self._open(\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/fsspec/implementations/local.py\", line 155, in _open\n    return LocalFileOpener(path, mode, fs=self, **kwargs)\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/fsspec/implementations/local.py\", line 250, in __init__\n    self._open()\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/fsspec/implementations/local.py\", line 255, in _open\n    self.f = open(self.path, mode=self.mode)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/0z/cvwxldvs5qjdzx5vn89pn9f40000gn/T/ipykernel_5175/345806381.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;31m#read data with dask\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0mdocs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_text\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloads\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'count:'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdocs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcount\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/base.py\u001B[0m in \u001B[0;36mcompute\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    286\u001B[0m         \u001B[0mdask\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbase\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    287\u001B[0m         \"\"\"\n\u001B[0;32m--> 288\u001B[0;31m         \u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraverse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    289\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    290\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/base.py\u001B[0m in \u001B[0;36mcompute\u001B[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001B[0m\n\u001B[1;32m    569\u001B[0m         \u001B[0mpostcomputes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__dask_postcompute__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    570\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 571\u001B[0;31m     \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mschedule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdsk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeys\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    572\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mrepack\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0ma\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresults\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpostcomputes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    573\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/multiprocessing.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(dsk, keys, num_workers, func_loads, func_dumps, optimize_graph, pool, chunksize, **kwargs)\u001B[0m\n\u001B[1;32m    217\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    218\u001B[0m         \u001B[0;31m# Run\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 219\u001B[0;31m         result = get_async(\n\u001B[0m\u001B[1;32m    220\u001B[0m             \u001B[0mpool\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msubmit\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    221\u001B[0m             \u001B[0mpool\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_max_workers\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/local.py\u001B[0m in \u001B[0;36mget_async\u001B[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001B[0m\n\u001B[1;32m    505\u001B[0m                             \u001B[0m_execute_task\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# Re-execute locally\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    506\u001B[0m                         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 507\u001B[0;31m                             \u001B[0mraise_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    508\u001B[0m                     \u001B[0mres\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mworker_id\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloads\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mres_info\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    509\u001B[0m                     \u001B[0mstate\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"cache\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mres\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/multiprocessing.py\u001B[0m in \u001B[0;36mreraise\u001B[0;34m(exc, tb)\u001B[0m\n\u001B[1;32m    107\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mreraise\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    108\u001B[0m         \u001B[0mexc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mremote_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 109\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    110\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Users/erdemdemir/Desktop/scalable-projects/ID2223-Final-Levent_Güner-Erdem_Demir/arxiv-metadata-oai-snapshot.json'\n\nTraceback\n---------\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/local.py\", line 220, in execute_task\n    result = _execute_task(task, data)\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/core.py\", line 119, in _execute_task\n    return func(*(_execute_task(a, cache) for a in args))\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/core.py\", line 119, in <genexpr>\n    return func(*(_execute_task(a, cache) for a in args))\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/core.py\", line 113, in _execute_task\n    return [_execute_task(a, cache) for a in arg]\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/core.py\", line 113, in <listcomp>\n    return [_execute_task(a, cache) for a in arg]\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/core.py\", line 119, in _execute_task\n    return func(*(_execute_task(a, cache) for a in args))\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/bag/core.py\", line 2440, in empty_safe_apply\n    _, part = peek(part)\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/toolz/itertoolz.py\", line 1000, in peek\n    item = next(iterator)\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/bag/core.py\", line 2012, in __next__\n    vals = [next(i) for i in self.iters]\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/bag/core.py\", line 2012, in <listcomp>\n    vals = [next(i) for i in self.iters]\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/dask/bag/text.py\", line 164, in file_to_blocks\n    with lazy_file as f:\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/fsspec/core.py\", line 103, in __enter__\n    f = self.fs.open(self.path, mode=mode)\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/fsspec/spec.py\", line 1030, in open\n    f = self._open(\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/fsspec/implementations/local.py\", line 155, in _open\n    return LocalFileOpener(path, mode, fs=self, **kwargs)\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/fsspec/implementations/local.py\", line 250, in __init__\n    self._open()\n  File \"/Users/erdemdemir/DataspellProjects/bert-arxiv/venv/lib/python3.9/site-packages/fsspec/implementations/local.py\", line 255, in _open\n    self.f = open(self.path, mode=self.mode)\n"
     ]
    }
   ],
   "source": [
    "#get data\n",
    "data_file = 'arxiv-metadata-oai-snapshot.json'\n",
    "\n",
    "def get_metadata():\n",
    "    with open(data_file, 'r') as f:\n",
    "        for line in f:\n",
    "            yield line\n",
    "\n",
    "\n",
    "#read data with dask\n",
    "docs = db.read_text(data_file).map(json.loads)\n",
    "print('count:',docs.count().compute())\n",
    "\n",
    "\n",
    "#see an instance example\n",
    "docs.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Convert to Pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get latest versions and convert to df\n",
    "\n",
    "get_latest_version = lambda x: x['versions'][-1]['created']\n",
    "\n",
    "# get only necessary fields\n",
    "trim = lambda x: {'id': x['id'],\n",
    "                  'title': x['title'],\n",
    "                  'category':x['categories'].split(' '),\n",
    "                  'abstract':x['abstract']}\n",
    "# filter for papers published on or after 2019-01-01\n",
    "columns = ['id','category','abstract']\n",
    "docs_df = (docs\n",
    "             .filter(lambda x: int(get_latest_version(x).split(' ')[3]) > 2018)\n",
    "             .map(trim)\n",
    "             .compute())\n",
    "\n",
    "# convert to pandas\n",
    "docs_df = pd.DataFrame(docs_df)\n",
    "\n",
    "# add general category. we are going to use as our target variable\n",
    "docs_df['general_category'] = docs_df.category.apply(lambda x:[a.split('.')[0] for a in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df['sub_category'] = docs_df.category.apply(lambda x:[a.split('.')[1] if ('.' in a) else a.split('.')[0]+'_nsc' for a in x])\n",
    "docs_df['new_category'] = docs_df.category.apply(lambda x:[[a.split('.')[0],a.split('.')[1]] if ('.' in a) else [a.split('.')[0],a.split('.')[0]+'_nsc'] for a in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Prepare Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare categories for prediction\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(docs_df.general_category)\n",
    "\n",
    "mlb_sub = MultiLabelBinarizer()\n",
    "labels_sub = mlb_sub.fit_transform(docs_df.sub_category)\n",
    "labels_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create category and sub-category dict\n",
    "\n",
    "cats_sub_cats = {}\n",
    "catvals = docs_df['new_category'].values\n",
    "for item in mlb.classes_:\n",
    "    cats_sub_cats[item] = []\n",
    "\n",
    "for i in range(len(docs_df['new_category'])):\n",
    "    for item in catvals[i]:\n",
    "        cats_sub_cats[item[0]].append(item[1])\n",
    "        \n",
    "for item in mlb.classes_:\n",
    "    cats_sub_cats[item] = list(set(cats_sub_cats[item]))\n",
    "cats_sub_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([docs_df[['abstract','title']], pd.DataFrame(labels), pd.DataFrame(labels_sub)], axis=1)\n",
    "df.columns = ['abstract','title'] + list(mlb.classes_) + list(mlb_sub.classes_)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Create Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create samples\n",
    "\n",
    "chosen_cols = ['cs','math','physics','cond-mat','astro-ph','quant-ph','hep-ph']\n",
    "df_filtered = df[(df['cs']==1) | (df['math']==1) | (df['physics']==1) | (df['cond-mat']==1) | (df['astro-ph']==1) | (df['quant-ph']==1) | (df['hep-ph']==1) ][chosen_cols+['abstract']]\n",
    "dfad = df_filtered.drop('abstract',axis=1)\n",
    "idxs = []\n",
    "for cat in chosen_cols:\n",
    "    print(cat)\n",
    "    sample_count=20000\n",
    "    if cat=='cs':\n",
    "        sample_count=15000\n",
    "        dfad['axissum'] = dfad.sum(axis=1)\n",
    "        id1 = dfad[(dfad[cat]==1) & dfad['axissum']==1].sample(sample_count).index\n",
    "        idxs.append(np.array(id1))\n",
    "        print(len(id1))\n",
    "    else:\n",
    "        id1 = df_filtered[df_filtered[cat]==1].sample(sample_count).index\n",
    "        idxs.append(np.array(id1))\n",
    "\n",
    "idx_list = list(set([j for i in idxs for j in i ]))\n",
    "df_filtered_new = df_filtered.loc[idx_list,chosen_cols+['abstract']]\n",
    "df_filtered_new[chosen_cols].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_new = df_filtered_new[['abstract', 'cs', 'math', 'physics', 'cond-mat',  'astro-ph', 'quant-ph',\n",
    "       'hep-ph']].sample(frac=1)\n",
    "\n",
    "\n",
    "train_size = int(len(df_filtered_new)*0.75)\n",
    "train_df = df_filtered_new[:train_size]\n",
    "test_df = df_filtered_new[train_size:]\n",
    "\n",
    "#save dfs\n",
    "\n",
    "train_df.to_csv('train_arxiv_2.csv',index=False)\n",
    "test_df.to_csv('test_arxiv_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Open Sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_arxiv_2.csv')\n",
    "test_df = pd.read_csv('test_arxiv_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.abstract\n",
    "y_train = train_df.drop('abstract',axis=1)\n",
    "X_test = test_df.abstract\n",
    "y_test = test_df.drop('abstract',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Clean and Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean\n",
    "ct = CleanText()\n",
    "X_train = ct.fit_transform(X_train)\n",
    "X_test = ct.transform(X_test)\n",
    "\n",
    "print('cleaned')\n",
    "\n",
    "\n",
    "#tokenization\n",
    "max_features = 10000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(X_train) #sadece train ile yap\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train) #train ve test için ayrı ayrı yap\n",
    "X_train = pad_sequences(X_train,maxlen=100) #train ve test için ayrı ayrı yap\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_test) #train ve test için ayrı ayrı yap\n",
    "X_test = pad_sequences(X_test,maxlen=100) #train ve test için ayrı ayrı yap\n",
    "\n",
    "print('tokenized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the LSTM model\n",
    "embed_dim = 64\n",
    "lstm_out = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim,input_length = X_train.shape[1]))\n",
    "model.add(LSTM(5))\n",
    "model.add(Dense(y_train.shape[1],activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# fit model\n",
    "batch_size = 128\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, epochs = 3, batch_size=batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Get Predictions & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = y_train.columns\n",
    "sums = y_test.sum(axis=1)\n",
    "\n",
    "class_map = {i:class_names[i] for i in range(len(class_names))}\n",
    "preds = model.predict(X_test) #predicteds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "sns.heatmap(mt.confusion_matrix(np.argmax(y_test.values[np.where(sums==1)[0]],axis=1),\n",
    "np.argmax(preds[np.where(sums==1)[0]],axis=1),normalize='true'),\n",
    "annot=True,\n",
    "fmt='.2f',\n",
    "xticklabels=class_names,\n",
    "yticklabels=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report\n",
    "clf_rep = mt.classification_report(y_test.astype(bool).values,(preds>0.4),target_names=class_names)\n",
    "\n",
    "print(clf_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/train_arxiv_2.csv')\n",
    "df = df.sample(frac=1).reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "label_cols = list(cols[2:])\n",
    "num_labels = len(label_cols)\n",
    "print('Label columns: ', label_cols)\n",
    "df['one_hot_labels'] = list(df[label_cols].values)\n",
    "labels = list(df.one_hot_labels.values)\n",
    "abstracts = list(df.abstract.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allenai/scibert_scivocab_uncased for SciBERT\n",
    "# bert-base-uncased for BERT Base Model\n",
    "\n",
    "max_length = 100 # due to GPU memory issues\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # tokenizer\n",
    "encodings = tokenizer.batch_encode_plus(abstracts,max_length=max_length,pad_to_max_length=True) # tokenizer's encoding method\n",
    "print('tokenizer outputs: ', encodings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = encodings['input_ids'] # tokenized and encoded sentences\n",
    "token_type_ids = encodings['token_type_ids'] # token type ids\n",
    "attention_masks = encodings['attention_mask'] # attention masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for stratification\n",
    "label_counts = df.one_hot_labels.astype(str).value_counts()\n",
    "single_freq = label_counts[label_counts==1].keys()\n",
    "single_freq_idxs = sorted(list(df[df.one_hot_labels.astype(str).isin(single_freq)].index), reverse=True)\n",
    "single_freq_input_ids = [input_ids.pop(i) for i in single_freq_idxs]\n",
    "single_freq_token_types = [token_type_ids.pop(i) for i in single_freq_idxs]\n",
    "single_freq_attention_masks = [attention_masks.pop(i) for i in single_freq_idxs]\n",
    "single_freq_labels = [labels.pop(i) for i in single_freq_idxs]\n",
    "\n",
    "# Use train_test_split to split our data into train and validation sets\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels, train_token_types, validation_token_types, train_masks, validation_masks = train_test_split(input_ids, labels, token_type_ids, attention_masks,\n",
    "                                                            random_state=42, test_size=0.1, stratify = labels)\n",
    "\n",
    "# Add single frequency data to train data\n",
    "train_inputs.extend(single_freq_input_ids)\n",
    "train_labels.extend(single_freq_labels)\n",
    "train_masks.extend(single_freq_attention_masks)\n",
    "train_token_types.extend(single_freq_token_types)\n",
    "\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "train_token_types = torch.tensor(train_token_types)\n",
    "\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "validation_token_types = torch.tensor(validation_token_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Iterator with DataLoader\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels, validation_token_types)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "torch.save(train_dataloader,'train_data_loader')\n",
    "torch.save(validation_dataloader,'validation_data_loader')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allenai/scibert_scivocab_uncased for SciBERT\n",
    "# bert-base-uncased for BERT Base Model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting custom optimization parameters. You may implement a scheduler here as well.\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters,lr=2e-5,correct_bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/0z/cvwxldvs5qjdzx5vn89pn9f40000gn/T/ipykernel_333/1167578801.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# trange for tracking the progress\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdesc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"Epoch\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m   \u001B[0;31m# Training\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'trange' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loss_set = []\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "# trange for tracking the progress\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "\n",
    "  # Training\n",
    "  \n",
    "  # Set our model to training mode (as opposed to evaluation mode)\n",
    "  model.train()\n",
    "\n",
    "  # Tracking variables\n",
    "  tr_loss = 0 #running loss\n",
    "  num_train_examples, num_train_steps = 0, 0\n",
    "  \n",
    "  # Train the data for one epoch\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    \n",
    "    batch = tuple(t.to(device) for t in batch) # Add batch to GPU\n",
    "    batch_input_ids, batch_input_mask, batch_labels, batch_token_types = batch\n",
    "    optimizer.zero_grad() # Clear gradients\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(batch_input_ids, token_type_ids=None, attention_mask=batch_input_mask)\n",
    "    logits = outputs[0]\n",
    "    loss_func = BCEWithLogitsLoss()\n",
    "    loss = loss_func(logits.view(-1,num_labels),batch_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
    "    train_loss_set.append(loss.item())    \n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update parameters and take a step using the computed gradient\n",
    "    optimizer.step()\n",
    "    # scheduler.step()\n",
    "    # Update tracking variables\n",
    "    tr_loss += loss.item()\n",
    "    num_train_examples += batch_input_ids.size(0)\n",
    "    num_train_steps += 1\n",
    "\n",
    "  print(\"Train loss: {}\".format(tr_loss/num_train_steps))\n",
    "\n",
    "  # Validation\n",
    "\n",
    "  # Put model in evaluation state to calculate loss on the validation set\n",
    "  model.eval()\n",
    "\n",
    "  logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "  # Predictions\n",
    "  for i, batch in enumerate(validation_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch) # Pass to GPU\n",
    "    # Get inputs from our dataloader\n",
    "    batch_input_ids, batch_input_mask, batch_labels, batch_token_types = batch\n",
    "    with torch.no_grad():\n",
    "      # Forward pass\n",
    "      outs = model(batch_input_ids, token_type_ids=None, attention_mask=batch_input_mask)\n",
    "      batch_logit_pred = outs[0]\n",
    "      pred_label = torch.sigmoid(batch_logit_pred)\n",
    "\n",
    "      batch_logit_pred = batch_logit_pred.detach().cpu().numpy()\n",
    "      pred_label = pred_label.to('cpu').numpy()\n",
    "      batch_labels = batch_labels.to('cpu').numpy()\n",
    "\n",
    "    tokenized_texts.append(batch_input_ids)\n",
    "    logit_preds.append(batch_logit_pred)\n",
    "    true_labels.append(batch_labels)\n",
    "    pred_labels.append(pred_label)\n",
    "\n",
    "  # Flatten outputs\n",
    "  pred_labels = [item for preds in pred_labels for item in preds]\n",
    "  true_labels = [item for trues in true_labels for item in trues]\n",
    "\n",
    "  # Calculate Accuracy\n",
    "  threshold = 0.5\n",
    "  pred_bools = [pl>threshold for pl in pred_labels]\n",
    "  true_bools = [tl==1 for tl in true_labels]\n",
    "  val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n",
    "  val_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
    "\n",
    "  print('F1 Validation Accuracy: {:.2f} %'.format(val_f1_accuracy))\n",
    "  print('Validation Accuracy: {:.2f} %'.format(val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for the future\n",
    "torch.save(model.state_dict(), '/content/drive/MyDrive/bert_model_arxiv') #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model to evaluate\n",
    "model.load_state_dict(torch.load('/content/drive/MyDrive/bert_model_arxiv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/content/drive/MyDrive/test_arxiv_2.csv')\n",
    "test_df['one_hot_labels'] = list(test_df[label_cols].values)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = list(test_df.one_hot_labels.values)\n",
    "test_abstracts = list(test_df.abstract.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode input data\n",
    "test_encodings = tokenizer.batch_encode_plus(test_abstracts,max_length=max_length,pad_to_max_length=True)\n",
    "test_input_ids = test_encodings['input_ids']\n",
    "test_token_type_ids = test_encodings['token_type_ids']\n",
    "test_attention_masks = test_encodings['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tensors & data loader from the data\n",
    "test_inputs = torch.tensor(test_input_ids)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "test_masks = torch.tensor(test_attention_masks)\n",
    "test_token_types = torch.tensor(test_token_type_ids)\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels, test_token_types)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "torch.save(test_dataloader,'test_data_loader')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put model into evaluation state to evaluate loss on the validation set\n",
    "model.eval()\n",
    "\n",
    "logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "# Predict\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "  batch_input_ids, batch_input_mask, batch_labels, batch_token_types = batch\n",
    "  with torch.no_grad():\n",
    "    # Forward pass\n",
    "    outs = model(batch_input_ids, token_type_ids=None, attention_mask=batch_input_mask)\n",
    "    batch_logit_pred = outs[0]\n",
    "    pred_label = torch.sigmoid(batch_logit_pred)\n",
    "\n",
    "    batch_logit_pred = batch_logit_pred.detach().cpu().numpy()\n",
    "    pred_label = pred_label.to('cpu').numpy()\n",
    "    batch_labels = batch_labels.to('cpu').numpy()\n",
    "\n",
    "  tokenized_texts.append(batch_input_ids)\n",
    "  logit_preds.append(batch_logit_pred)\n",
    "  true_labels.append(batch_labels)\n",
    "  pred_labels.append(pred_label)\n",
    "\n",
    "# Flatten outputs\n",
    "tokenized_texts = [item for tok_text in tokenized_texts for item in tok_text]\n",
    "pred_labels = [item for preds in pred_labels for item in preds]\n",
    "true_labels = [item for trues in true_labels for item in trues]\n",
    "\n",
    "true_bools = [tl==1 for tl in true_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bools = [pl>0.5 for pl in pred_labels] # Apply threshold\n",
    "\n",
    "\n",
    "print('Test F1 Accuracy: ', f1_score(true_bools, pred_bools,average='micro'))\n",
    "print('Test Flat Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\n",
    "clf_report = classification_report(true_bools,pred_bools,target_names=label_cols)\n",
    "pickle.dump(clf_report, open('classification_report.txt','wb')) #save report\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.4 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "true_bools = np.array(true_bools)\n",
    "pred_bools = np.array(pred_bools)\n",
    "\n",
    "sums = true_bools.sum(axis=1)\n",
    "yt = np.argmax(true_bools[np.where(sums==1)[0]],axis=1)\n",
    "yp = np.argmax(pred_bools[np.where(sums==1)[0]],axis=1)\n",
    "sns.heatmap(confusion_matrix(yt,yp,normalize='true'),annot=True,fmt='.2f',xticklabels=label_cols,yticklabels=label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.5 Create Output DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = dict(zip(range(7),label_cols))\n",
    "print(idx2label)\n",
    "\n",
    "# Getting indices of where boolean one hot vector true_bools is True so we can use idx2label to gather label names\n",
    "true_label_idxs, pred_label_idxs=[],[]\n",
    "for vals in true_bools:\n",
    "  true_label_idxs.append(np.where(vals)[0].flatten().tolist())\n",
    "for vals in pred_bools:\n",
    "  pred_label_idxs.append(np.where(vals)[0].flatten().tolist())\n",
    "\n",
    "# Gathering vectors of label names using idx2label\n",
    "true_label_texts, pred_label_texts = [], []\n",
    "for vals in true_label_idxs:\n",
    "  if vals:\n",
    "    true_label_texts.append([idx2label[val] for val in vals])\n",
    "  else:\n",
    "    true_label_texts.append(vals)\n",
    "\n",
    "for vals in pred_label_idxs:\n",
    "  if vals:\n",
    "    pred_label_texts.append([idx2label[val] for val in vals])\n",
    "  else:\n",
    "    pred_label_texts.append(vals)\n",
    "\n",
    "# Decoding input ids to comment text\n",
    "abstracts = [tokenizer.decode(text,skip_special_tokens=True,clean_up_tokenization_spaces=False) for text in tokenized_texts]\n",
    "\n",
    "# Converting lists to df\n",
    "comparisons_df = pd.DataFrame({'abstract': abstracts, 'true_labels': true_label_texts, 'pred_labels':pred_label_texts})\n",
    "comparisons_df.to_csv('comparisons.csv')\n",
    "comparisons_df.head()\n",
    "\n",
    "comparisons_df.to_csv(\"/content/drive/MyDrive/comparisons.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}